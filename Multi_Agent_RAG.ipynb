{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Document & Multi-Agent RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "import re\n",
    "from glob import glob\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproceesing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function makes sure the files namming are compatabile to be used as vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sanitize names\n",
    "def sanitize_name(name: str) -> str:\n",
    "    # Replace spaces with underscores\n",
    "    name = name.replace(\" \", \"_\")\n",
    "    # Remove any character that is not alphanumeric, underscore, or dash\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]\", \"\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_headers(lines):\n",
    "    \"\"\"\n",
    "    Processes a list of lines from a Markdown file and merges consecutive header lines.\n",
    "    A header is defined as a line starting with 1-6 '#' characters followed by a space.\n",
    "    When two or more header lines are consecutive, they are merged into a single header.\n",
    "    The first header's level is preserved and the content from the subsequent headers is appended.\n",
    "    \"\"\"\n",
    "    merged_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].rstrip(\"\\n\")\n",
    "        if re.match(r'^#{1,6}\\s', line):\n",
    "            header_line = line\n",
    "            j = i + 1\n",
    "            while j < len(lines) and re.match(r'^#{1,6}\\s', lines[j]):\n",
    "                match = re.match(r'^(#{1,6})\\s+(.*)', lines[j])\n",
    "                if match:\n",
    "                    header_text = match.group(2).strip()\n",
    "                    header_line = header_line.rstrip() + \" \" + header_text\n",
    "                j += 1\n",
    "            merged_lines.append(header_line + \"\\n\")\n",
    "            i = j  # Skip all merged header lines\n",
    "        else:\n",
    "            merged_lines.append(line + \"\\n\")\n",
    "            i += 1\n",
    "    return merged_lines\n",
    "\n",
    "def clean_markdown_files(input_directory, output_directory=None):\n",
    "    \"\"\"\n",
    "    Iterates through all Markdown (.md) files in the input_directory,\n",
    "    merges consecutive header lines in each file, and writes the cleaned content\n",
    "    to the output_directory. If output_directory is not provided, a subfolder\n",
    "    called 'cleaned' will be created inside the input_directory.\n",
    "    \"\"\"\n",
    "    if output_directory is None:\n",
    "        output_directory = os.path.join(input_directory, \"cleaned\")\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "        \n",
    "    md_files = glob(os.path.join(input_directory, \"*.md\"))\n",
    "    for md_file in md_files:\n",
    "        with open(md_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        cleaned_lines = merge_consecutive_headers(lines)\n",
    "        output_file = os.path.join(output_directory, os.path.basename(md_file))\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(cleaned_lines)\n",
    "        print(f\"Cleaned file written to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function merges consecutiv header to fix chunking issues. Call the function and set the correct path for the files. \n",
    "After running, a file named 'cleaned' will be created in the same directory of the fiels, use the files in the cleaned folder as the path for following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = \".\\التقارير السنوية\" # e.g., \"./markdown_files\"\n",
    "\n",
    "# # Clean the Markdown files by merging consecutive headers.\n",
    "# clean_markdown_files(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up LLM & Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the path here is the path of cleaned files from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_types = {\n",
    "    \"annual_reports\": \"Data/التقارير السنوية\",        # Folder containing 8 markdown files\n",
    "    \"balance_of_banks\": \"Data/ميزان المدفوعات\",        # Folder containing 10 markdown files\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Lowe-Level Agents With Query Engine Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionaries to hold low-level agents and their top-level tools\n",
    "low_level_agents = {}\n",
    "low_level_tools = {}\n",
    "\n",
    "# We'll use a SentenceSplitter to break up the markdown text into nodes\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "node_parser = MarkdownNodeParser()\n",
    "\n",
    "# For each report type, build file-level tools and then group them into a low-level agent.\n",
    "for report_type, folder_path in report_types.items():\n",
    "    # Sanitize the report type name for tool naming\n",
    "    safe_report_type = sanitize_name(report_type)\n",
    "    \n",
    "    # Get a list of markdown files in the directory\n",
    "    file_paths = [str(path) for path in Path(folder_path).glob(\"*.md\")]\n",
    "    file_tools = []  # This will hold a tool per file in the report type\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        # Load the markdown document from the file\n",
    "        docs = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "        # Split the document into nodes for finer granularity\n",
    "        nodes = node_parser.get_nodes_from_documents(docs)\n",
    "        \n",
    "        # Create or load a vector index for this file\n",
    "        # We persist the index in a subdirectory named after the file (without extension)\n",
    "        file_stem = Path(file_path).stem\n",
    "        safe_file_stem = sanitize_name(file_stem)\n",
    "        persist_dir = f\"./data/{safe_report_type}/{safe_file_stem}\"\n",
    "        if not os.path.exists(persist_dir):\n",
    "            vector_index = VectorStoreIndex(nodes)\n",
    "            vector_index.storage_context.persist(persist_dir=persist_dir)\n",
    "        else:\n",
    "            from llama_index.core import load_index_from_storage, StorageContext\n",
    "            vector_index = load_index_from_storage(\n",
    "                StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "            )\n",
    "        \n",
    "        # Create the vector query engine for this file\n",
    "        vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
    "        \n",
    "        # Wrap the query engine in a tool, labeling it with the sanitized file name\n",
    "        file_tool = QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=f\"tool_{safe_report_type}_{safe_file_stem}\",\n",
    "                description=f\"Tool for the report file '{file_stem}' in {report_type.replace('_', ' ')}.\"\n",
    "            ),\n",
    "        )\n",
    "        file_tools.append(file_tool)\n",
    "    \n",
    "    # Create a low-level agent for this report type that aggregates all file-level tools\n",
    "    from llama_index.agent.openai import OpenAIAgent\n",
    "    function_llm = OpenAI(model=\"gpt-4o\")\n",
    "    low_level_agent = OpenAIAgent.from_tools(\n",
    "        file_tools,\n",
    "        llm=function_llm,\n",
    "        verbose=True,\n",
    "        system_prompt=(\n",
    "            f\"You are a specialized agent designed to answer queries about {report_type.replace('_', ' ')}. \"\n",
    "            \"You must ALWAYS use one of the provided tools and never rely on prior knowledge.\"\n",
    "        ),\n",
    "    )\n",
    "    low_level_agents[report_type] = low_level_agent\n",
    "    \n",
    "    # Create a top-level tool for this low-level agent with a sanitized name\n",
    "    report_tool = QueryEngineTool(\n",
    "        query_engine=low_level_agent,\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"agent_tool_{safe_report_type}\",\n",
    "            description=f\"Tool for answering queries about {report_type.replace('_', ' ')} financial reports.\"\n",
    "        ),\n",
    "    )\n",
    "    low_level_tools[report_type] = report_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = list(low_level_tools.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Top-Level Agent: Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step creates an index for the tools to be treated as text so that they can be retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ObjectIndex over the low-level agent tools\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the top-level agent that retrieves the right low-level agent based on the query\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "top_agent = OpenAIAgent.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    system_prompt=(\n",
    "        \"You are a top-level agent designed to answer queries about financial data from multiple report types. \"\n",
    "        \"Based on the query, select the appropriate tool to use (e.g., annual reports or balance of banks).\"\n",
    "        \"Always use the selected tool and never rely on prior knowledge.\"\n",
    "        \"Queries should be phrased in the same language as the prompt.\"\n",
    "        \"Always respond in arabic\"\n",
    "        \"If the response is from the tool is not optimal, change the tool untill you find satisfactory response\"\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples for one top-level OpenAI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: ماهي نسبة البطالة في التقارير السنوية لعام 2010؟\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\":\"نسبة البطالة في التقارير السنوية لعام 2010\"}\n",
      "Added user message to memory: نسبة البطالة في التقارير السنوية لعام 2010\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2010 with args: {\n",
      "  \"input\": \"unemployment rate\"\n",
      "}\n",
      "Got output: The unemployment rates in industrialized countries saw a noticeable increase in 2010 compared to 2009. The rates were 8.3% in 2010, up from 8.0% in 2009. In the Eurozone countries, the rate rose from 9.4% to 10.0%. The United States saw an increase from 9.3% in 2009 to 9.6% in 2010, while the United Kingdom's rate went up from 7.5% to 7.8%. Japan's unemployment rate remained unchanged at 5.1%.\n",
      "========================\n",
      "\n",
      "Got output: معدلات البطالة في البلدان المصنعة شهدت زيادة ملحوظة في عام 2010 مقارنة بعام 2009. كانت النسبة 8.3% في عام 2010، مقابل 8.0% في عام 2009. في دول منطقة اليورو، ارتفعت النسبة من 9.4% إلى 10.0%. شهدت الولايات المتحدة زيادة من 9.3% في عام 2009 إلى 9.6% في عام 2010، بينما ارتفعت نسبة المملكة المتحدة من 7.5% إلى 7.8%. بينما بقيت نسبة البطالة في اليابان ثابتة عند 5.1%.\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"ماهي نسبة البطالة في التقارير السنوية لعام 2010؟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 55c0aa8d-4aaa-412e-ad21-fbbcd91fd517\n",
      "Text: ## البطالة •    شهدت معدلات البطالة في الدول الصناعية عام 2010\n",
      "زيادة ملحوظة حيث بلغت 8.3% مقابل 8.0% عام 2009، وارتفعت في دول منطقة\n",
      "اليورو من 9.4% إلى 10.0%. كما ارتفع معدل البطالة في الولايات المتحدة\n",
      "الأمريكية من 9.3% في عام 2009 إلى 9.6% في عام 2010، وفي المملكة\n",
      "المتحدة من 7.5% إلى 7.8%. أما معدل البطالة في اليابان فقد ظل على ما هو\n",
      "عليه عند 5.1%.\n",
      "Score:  0.404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: قارن بين معدلات التضخم في التقارير السنوية لعام 2013 وعام 2014\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\": \"معدل التضخم لعام 2013\"}\n",
      "Added user message to memory: معدل التضخم لعام 2013\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2013 with args: {\"input\":\"معدل التضخم لعام 2013\"}\n",
      "Got output: معدل التضخم لعام 2013 هو 6.2%.\n",
      "========================\n",
      "\n",
      "Got output: معدل التضخم لعام 2013 هو 6.2%.\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\": \"معدل التضخم لعام 2014\"}\n",
      "Added user message to memory: معدل التضخم لعام 2014\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2014 with args: {\"input\":\"ما هو معدل التضخم لعام 2014؟\"}\n",
      "Got output: معدل التضخم لعام 2014 بلغ 2.4% وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك.\n",
      "========================\n",
      "\n",
      "Got output: معدل التضخم لعام 2014 بلغ 2.4% وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك.\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"قارن بين معدلات التضخم في التقارير السنوية لعام 2013 وعام 2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 53401fa8-6b80-47d4-acd7-eaedb8525a95\n",
      "Text: ## معدل التضخم :    استناداً إلى بيانات مصلحة الإحصاء والتعداد،\n",
      "فإن معدل التضخم وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك بلغ\n",
      "2.4% في نهاية عام 2014، حيث ارتفع الرقم القياسي لأسعار المستهلك من\n",
      "163.7 عام 2013 إلى 167.7 عام 2014. و تركز هذا الارتفاع في أسعار مجموعة\n",
      "المواد الغذائية والمشروبات والتبغ بنسبة 4.5%، وارتفع الرقم القياسي\n",
      "لمجموعة ال...\n",
      "Score:  0.636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: ماهي النسبة المئوية للناتج المحلي الإجمالي في التقارير السنوية لعام 2013؟\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\":\"الناتج المحلي الإجمالي لعام 2013\"}\n",
      "Added user message to memory: الناتج المحلي الإجمالي لعام 2013\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2013 with args: {\"input\":\"الناتج المحلي الإجمالي لعام 2013\"}\n",
      "Got output: الناتج المحلي الإجمالي الاسمي لعام 2013 سجل ارتفاعًا بنسبة 20.8%، حيث بلغت قيمة الناتج المحلي النفطي 4284 مليار دينار، بينما بلغ الناتج المحلي غير النفطي حوالي 348 مليار دينار.\n",
      "========================\n",
      "\n",
      "Got output: الناتج المحلي الإجمالي الاسمي لعام 2013 سجل ارتفاعًا بنسبة 20.8%. بلغت قيمة الناتج المحلي النفطي 4284 مليار دينار، بينما بلغ الناتج المحلي غير النفطي حوالي 348 مليار دينار.\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"ماهي النسبة المئوية للناتج المحلي الإجمالي في التقارير السنوية لعام 2013؟\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent Runner & Agent Worker with loop reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_retreiver = obj_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner\n",
    "llm=OpenAI(model=\"gpt-4o\",\n",
    "    system_prompt=\"You are a top-level agent designed to answer queries about financial data from multiple report types.\"\n",
    "        \"Based on the query, select the appropriate tool to use (e.g., annual reports or balance of banks).\"\n",
    "        \"Always use the selected tool and never rely on prior knowledge.\"\n",
    "           )\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    tool_retriever=obj_retreiver,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: قارن بين معدلات التضخم في التقارير السنوية لعام 2013 وعام 2014\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\": \"\\u0645\\u0639\\u062f\\u0644 \\u0627\\u0644\\u062a\\u0636\\u062e\\u0645 \\u0641\\u064a \\u0627\\u0644\\u062a\\u0642\\u0631\\u064a\\u0631 \\u0627\\u0644\\u0633\\u0646\\u0648\\u064a \\u0644\\u0639\\u0627\\u0645 2013\"}\n",
      "Added user message to memory: معدل التضخم في التقرير السنوي لعام 2013\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2013 with args: {\"input\":\"معدل التضخم\"}\n",
      "Got output: في عام 2013، ارتفع معدل التضخم ليصل إلى 6.1% مقارنة بـ 2.6% في عام 2012. هذا الارتفاع يعزى إلى زيادة الإنفاق العام، وخاصة الإنفاق الجاري.\n",
      "========================\n",
      "\n",
      "=== Function Output ===\n",
      "في عام 2013، ارتفع معدل التضخم ليصل إلى 6.1% مقارنة بـ 2.6% في عام 2012. هذا الارتفاع يعزى إلى زيادة الإنفاق العام، وخاصة الإنفاق الجاري.\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\": \"\\u0645\\u0639\\u062f\\u0644 \\u0627\\u0644\\u062a\\u0636\\u062e\\u0645 \\u0641\\u064a \\u0627\\u0644\\u062a\\u0642\\u0631\\u064a\\u0631 \\u0627\\u0644\\u0633\\u0646\\u0648\\u064a \\u0644\\u0639\\u0627\\u0645 2014\"}\n",
      "Added user message to memory: معدل التضخم في التقرير السنوي لعام 2014\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2014 with args: {\"input\":\"معدل التضخم\"}\n",
      "Got output: معدل التضخم في نهاية عام 2014 بلغ 2.4% وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك.\n",
      "========================\n",
      "\n",
      "=== Function Output ===\n",
      "معدل التضخم في نهاية عام 2014 بلغ 2.4% وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك.\n",
      "=== LLM Response ===\n",
      "في عام 2013، ارتفع معدل التضخم ليصل إلى 6.1% مقارنة بـ 2.6% في عام 2012. هذا الارتفاع يعزى إلى زيادة الإنفاق العام، وخاصة الإنفاق الجاري.\n",
      "\n",
      "أما في نهاية عام 2014، فقد بلغ معدل التضخم 2.4% وفقاً لمؤشر الرقم القياسي العام لأسعار المستهلك. \n",
      "\n",
      "بالمقارنة، يمكن ملاحظة أن معدل التضخم انخفض بشكل ملحوظ في عام 2014 مقارنة بعام 2013.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"قارن بين معدلات التضخم في التقارير السنوية لعام 2013 وعام 2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: في عام 2008, ماهي نسبة البطالة في امريكا وماهي قيمة الحساب الجاري في ليبيا؟\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_annual_reports with args: {\"input\": \"\\u0646\\u0633\\u0628\\u0629 \\u0627\\u0644\\u0628\\u0637\\u0627\\u0644\\u0629 \\u0641\\u064a \\u0627\\u0645\\u0631\\u064a\\u0643\\u0627 \\u0639\\u0627\\u0645 2008\"}\n",
      "Added user message to memory: نسبة البطالة في امريكا عام 2008\n",
      "=== Calling Function ===\n",
      "Calling function: tool_annual_reports_annual_report_2008 with args: {\"input\":\"نسبة البطالة في امريكا عام 2008\"}\n",
      "Got output: نسبة البطالة في الولايات المتحدة الأمريكية عام 2008 كانت 5.8%.\n",
      "========================\n",
      "\n",
      "=== Function Output ===\n",
      "نسبة البطالة في الولايات المتحدة الأمريكية عام 2008 كانت 5.8%.\n",
      "=== Calling Function ===\n",
      "Calling function: agent_tool_balance_of_banks with args: {\"input\": \"\\u0642\\u064a\\u0645\\u0629 \\u0627\\u0644\\u062d\\u0633\\u0627\\u0628 \\u0627\\u0644\\u062c\\u0627\\u0631\\u064a \\u0641\\u064a \\u0644\\u064a\\u0628\\u064a\\u0627 \\u0639\\u0627\\u0645 2008\"}\n",
      "Added user message to memory: قيمة الحساب الجاري في ليبيا عام 2008\n",
      "=== Calling Function ===\n",
      "Calling function: tool_balance_of_banks___2008 with args: {\"input\":\"قيمة الحساب الجاري في ليبيا\"}\n",
      "Got output: قيمة الحساب الجاري في ليبيا لعام 2008 كانت 45,985.0 مليون دينار.\n",
      "========================\n",
      "\n",
      "=== Function Output ===\n",
      "قيمة الحساب الجاري في ليبيا لعام 2008 كانت 45,985.0 مليون دينار.\n",
      "=== LLM Response ===\n",
      "في عام 2008، كانت نسبة البطالة في الولايات المتحدة الأمريكية 5.8%. أما قيمة الحساب الجاري في ليبيا فكانت 45,985.0 مليون دينار.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"في عام 2008, ماهي نسبة البطالة في امريكا وماهي قيمة الحساب الجاري في ليبيا؟\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
